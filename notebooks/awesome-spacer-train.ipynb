{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from random import shuffle\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import chain\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid character set\n",
    "complete_kor_range = range(0xac00, 0xd7a4)\n",
    "complete_eng_range = range(0x0041, 0x007b)\n",
    "#punctuations = '~!@#$%^&*()-_=+{}[];:\\'\"<>,./?'\n",
    "numbers = '0123456789'\n",
    "\n",
    "idx_to_chr = []\n",
    "chr_to_idx = {}\n",
    "# The first few indices are reserved\n",
    "idx_to_chr.append('<PAD>')\n",
    "idx_to_chr.append('<START>')\n",
    "idx_to_chr.append('<UNK>') # unknown\n",
    "\n",
    "# A list mapping indices to words\n",
    "idx_to_chr.extend(numbers)\n",
    "#idx_to_chr.extend(punctuations)\n",
    "for i in chain(complete_kor_range, complete_eng_range):\n",
    "    idx_to_chr.append(chr(i))\n",
    "\n",
    "# A dictionary mapping charactes to integer indices\n",
    "for v, k in enumerate(idx_to_chr):\n",
    "    chr_to_idx[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string(s):\n",
    "    encoded = []\n",
    "    for c in s:\n",
    "        try:\n",
    "            idx = chr_to_idx[c]\n",
    "        except:\n",
    "            idx = chr_to_idx['<UNK>']\n",
    "        encoded.append(idx)\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def get_label(s, idx=0):\n",
    "    label = []\n",
    "    while True:\n",
    "        try:\n",
    "            next_ch = s[idx + 1]\n",
    "        except:\n",
    "            # End of sentence\n",
    "            label.append(0)\n",
    "            break\n",
    "        if next_ch == ' ':\n",
    "            label.append(1)\n",
    "            idx += 2\n",
    "        else:\n",
    "            label.append(0)\n",
    "            idx += 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(filenames, batch_size=64, max_text_len=200):\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    \n",
    "    for p in tqdm(filenames):\n",
    "        # Compiled regex to filter tags\n",
    "        treg = re.compile('<\\w*>|</\\w*>')\n",
    "        # Compiled regex to filter whitespaces\n",
    "        wreg = re.compile(' ')\n",
    "        with open(p, 'r', encoding='utf-8') as f:\n",
    "            # Parse html file\n",
    "            html = f.readlines()\n",
    "            html = ''.join(html)\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            # Use paragraphs only\n",
    "            texts = soup.find_all('p')\n",
    "            texts = [treg.sub('', str(t)).strip() for t in texts]\n",
    "            # Filter zero length input sentences\n",
    "            # and convert to lowercase\n",
    "            texts = [t.lower() for t in texts if t]\n",
    "\n",
    "            # Compute labels\n",
    "            labels = [get_label(t) for t in texts]\n",
    "            # Remove whitespaces\n",
    "            texts = [wreg.sub('', str(t)) for t in texts]\n",
    "            texts = [encode_string(t) for t in texts]\n",
    "\n",
    "            X_batch += texts\n",
    "            y_batch += labels\n",
    "    \n",
    "    X_batch = pad_sequences(X_batch, maxlen=max_text_len, \n",
    "                            padding='post', truncating='post',\n",
    "                            value=chr_to_idx['<PAD>'])\n",
    "    y_batch = pad_sequences(y_batch, maxlen=max_text_len, \n",
    "                            padding='post', truncating='post',\n",
    "                            value=chr_to_idx['<PAD>'])\n",
    "    \n",
    "    return (X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 2241 files.\n",
      "Using 100 files for training.\n",
      "Using 20 files for validation.\n"
     ]
    }
   ],
   "source": [
    "filenames = glob('sejong-corpus/corpus-utf8/*.txt')\n",
    "shuffle(filenames)\n",
    "\n",
    "train_filenames = filenames[:100]\n",
    "val_filenames = filenames[100:120]\n",
    "#test_filenames = filenames[2000:]\n",
    "\n",
    "print('Total {} files.'.format(len(filenames)))\n",
    "print('Using {} files for training.'.format(len(train_filenames)))\n",
    "print('Using {} files for validation.'.format(len(val_filenames)))\n",
    "#print('Using {} files for test.'.format(len(test_filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.42it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (127150, 200)\n",
      "y_train.shape:  (127150, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:09<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val.shape:  (44567, 200)\n",
      "y_val.shape:  (44567, 200)\n"
     ]
    }
   ],
   "source": [
    "max_text_len = 200\n",
    "\n",
    "X_train, y_train = build_dataset(train_filenames, max_text_len=max_text_len)\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "\n",
    "X_val, y_val = build_dataset(val_filenames, max_text_len=max_text_len)\n",
    "print('X_val.shape: ', X_val.shape)\n",
    "print('y_val.shape: ', y_val.shape)\n",
    "\n",
    "#X_test, y_test = build_dataset(test_filenames, max_text_len=max_text_len)\n",
    "#print('X_test.shape: ', X_test.shape)\n",
    "#print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded string\n",
      "[  378 10905  7013  7090  7646  6621  5417   378 10849    13   965  1697\n",
      "   144  4353  6501  1777  1697  6565   573  1697  7041  3092  1777     2\n",
      " 10601  4245  6989   517  7646  6507  6993  7629  1189  1777    13  4689\n",
      "  1757 10233  7090  6993  1915  6989  6709  5326  6485  6621  5417   378\n",
      " 10849   848  7041 10569  6593  7061   573  6621    13  4353  1749   378\n",
      " 10849 10233   573    13  3541  8805 10009  6453  5081  3517   144  7041\n",
      "  1189  7061  2300  7041  5529  4354 10597   153  7441  6993  7629  6593\n",
      "  1189  5417   848  7041 10569  6613  1697  1917     2   517   245  7041\n",
      "     5     3  5449  9981  4101  9533  7202  2001  7013  5305  7041  3465\n",
      "  2141   237 10601 10233  7090  6485  6621  6538     4     3     3 10198\n",
      "  8177  2085   153  7185 10013   378 10849   848  7041  2953  1697   144\n",
      "  7041  1777     2  7041  3069  6709  5326  7041  5669  5882    41    13\n",
      "  2085  1697  1917     2  7049   969  2289  7041   517   848  6993 10597\n",
      "  1189 10597  1189  4689  1757  4374  7629  6621  1793  6481  5326  7069\n",
      "  6621  1328   237  7061  1889  2953  1697   144     2     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n",
      "Encoded label\n",
      "[0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 1 0\n",
      " 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
      " 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "When converted back to string\n",
      "국회의장 집에서 국화 가꾸는 것 보았다는 얘기는 이렇다<UNK> 한 번은 그 집 앞을 지나다가 비닐 포장을 덮은 온상 안에서 국화꽃이 피어 있기에 가 보니 국화 포기가 마치 파씨 뿌린 것이 나 있듯이 소복하게 줄을 지어 나서 꽃이 피었는데<UNK> 그 골이 20센티미터 정도의 사이를 두고 한 포장 안에 약 100평쯤 되게 전판 국화꽃이라는 것이다<UNK> 이런 온상이 수십 개가 되는데<UNK> 일꾼들이 그 꽃을 하나하나 비닐봉지에 담아 상자에 넣고 있더라는 것<UNK><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>"
     ]
    }
   ],
   "source": [
    "idx = 99\n",
    "print('Encoded string')\n",
    "print(X_train[idx])\n",
    "print('\\nEncoded label')\n",
    "print(y_train[idx])\n",
    "\n",
    "print('\\nWhen converted back to string')\n",
    "for i, c in enumerate(X_train[idx]):\n",
    "    print(idx_to_chr[c], end='')\n",
    "    if y_train[idx][i] == 1:\n",
    "        print(' ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filter_nums, filter_sizes):\n",
    "    \"\"\"A convolution block\"\"\"\n",
    "    conv_blocks = []\n",
    "\n",
    "    for fn, fs in zip(filter_nums, filter_sizes):\n",
    "        conv = layers.Conv1D(filters=fn,\n",
    "                             kernel_size=fs,\n",
    "                             padding='same',\n",
    "                             activation='relu',\n",
    "                             strides=1)(x)\n",
    "        #conv = layers.GlobalMaxPooling1D()(conv)\n",
    "        conv_blocks.append(conv)\n",
    "\n",
    "    return conv_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 200, 100)     1124300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 200, 256)     102656      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 200, 256)     153856      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 200, 256)     205056      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 200, 256)     256256      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 200, 256)     307456      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 200, 1280)    0           conv1d[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 200, 100)     552400      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 200, 50)      30200       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 200, 300)     15300       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 200, 300)     0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 200, 150)     45150       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 200, 1)       151         time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 200)          0           time_distributed_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 2,792,781\n",
      "Trainable params: 2,792,781\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "USE_MULTI_GPU = True\n",
    "\n",
    "def Model():\n",
    "    inputs = layers.Input(shape=(max_text_len,))\n",
    "    x = layers.Embedding(len(idx_to_chr), 100, input_length=max_text_len)(inputs)\n",
    "\n",
    "    blocks = conv_block(x, filter_nums=(256, 256, 256, 256, 256), \n",
    "                           filter_sizes=(4, 6, 8, 10, 12))\n",
    "    x = layers.Concatenate()(blocks)\n",
    "    x = layers.LSTM(100, \n",
    "                    dropout=0.3,\n",
    "                    #recurrent_dropout=0.3,\n",
    "                    return_sequences=True)(x)\n",
    "    x = layers.LSTM(50,\n",
    "                    dropout=0.1,\n",
    "                    #recurrent_dropout=0.1,\n",
    "                    return_sequences=True)(x)\n",
    "\n",
    "    x = layers.TimeDistributed(layers.Dense(300, activation='relu'))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.TimeDistributed(layers.Dense(150, activation='relu'))(x)\n",
    "    x = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(x)\n",
    "    x = layers.Reshape((200,))(x)\n",
    "\n",
    "    model = models.Model(inputs, x)\n",
    "\n",
    "    return model\n",
    "\n",
    "if USE_MULTI_GPU:\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    #mirrored_strategy = tf.distribute.get_strategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        model = Model()\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "                               #tf.metrics.Precision(),\n",
    "                               #tf.metrics.Recall(),\n",
    "                               #tf.metrics.AUC()])\n",
    "\n",
    "        model.summary()\n",
    "else:\n",
    "    model = Model()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "                           #tf.metrics.Precision(),\n",
    "                           #tf.metrics.Recall(),\n",
    "                           #tf.metrics.AUC()])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_DIR_PATH = './models'\n",
    "if not os.path.exists(MODEL_SAVE_DIR_PATH):\n",
    "    os.makedir(MODEL_SAVE_DIR_PATH)\n",
    "\n",
    "model_path = os.path.join(MODEL_SAVE_DIR_PATH, '{epoch:02d}-{val_loss:.4f}-{val_accuracy:.4f}.hdf5')\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute global batch size using number of replicas.\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "global_batch_size = (BATCH_SIZE_PER_REPLICA *\n",
    "                     mirrored_strategy.num_replicas_in_sync)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(1024)\n",
    "train_dataset = train_dataset.batch(global_batch_size)\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "valid_dataset = valid_dataset.batch(global_batch_size)\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0704 03:37:24.035841 139675267188544 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 496 steps, validate on 174 steps\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object distributed_scope at 0x7f04f0552518>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dustin/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\", line 1035, in distributed_scope\n",
      "    yield\n",
      "  File \"/home/dustin/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 306, in __exit__\n",
      "    exception_type, exception_value, traceback)\n",
      "  File \"/home/dustin/anaconda3/envs/tf2/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/home/dustin/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2709, in variable_creator_scope\n",
      "    yield\n",
      "  File \"/home/dustin/anaconda3/envs/tf2/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/home/dustin/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2870, in _variable_creator_scope\n",
      "    if self._thread_local._variable_creator_stack is not new:  # pylint: disable=protected-access\n",
      "AttributeError: '_thread._local' object has no attribute '_variable_creator_stack'\n",
      "W0704 03:37:33.193493 139675267188544 cross_device_ops.py:764] Efficient allreduce is not supported for 1 IndexedSlices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495/496 [============================>.] - ETA: 3s - loss: 0.0596 - accuracy: 0.9753\n",
      "Epoch 00001: val_loss improved from 0.03310 to 0.02557, saving model to ./models/01-0.0256-0.9901.hdf5\n",
      "496/496 [==============================] - 1604s 3s/step - loss: 0.0596 - accuracy: 0.9753 - val_loss: 0.0256 - val_accuracy: 0.9901\n",
      "Epoch 2/3\n",
      "495/496 [============================>.] - ETA: 3s - loss: 0.0529 - accuracy: 0.9783\n",
      "Epoch 00002: val_loss improved from 0.02557 to 0.02230, saving model to ./models/02-0.0223-0.9917.hdf5\n",
      "496/496 [==============================] - 1586s 3s/step - loss: 0.0529 - accuracy: 0.9783 - val_loss: 0.0223 - val_accuracy: 0.9917\n",
      "Epoch 3/3\n",
      "157/496 [========>.....................] - ETA: 17:40 - loss: 0.0291 - accuracy: 0.9888"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-27d2438642e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mglobal_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributed_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    402\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \"\"\"\n\u001b[1;32m    588\u001b[0m     return self._call_flat(\n\u001b[0;32m--> 589\u001b[0;31m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0m\u001b[1;32m    590\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m    591\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=3,\n",
    "                    validation_data=valid_dataset,\n",
    "                    steps_per_epoch=len(y_train)//global_batch_size,\n",
    "                    validation_steps=len(y_val)//global_batch_size,\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-GPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125 steps, validate on 44 steps\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0704 03:09:39.358717 139658235209472 deprecation.py:323] From /home/dustin/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0704 03:09:46.942218 139675267188544 cross_device_ops.py:764] Efficient allreduce is not supported for 1 IndexedSlices\n",
      "W0704 03:09:57.949560 139675267188544 cross_device_ops.py:764] Efficient allreduce is not supported for 1 IndexedSlices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/125 [============================>.] - ETA: 7s - loss: 0.1645 - accuracy: 0.9317 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0704 03:24:52.995044 139675267188544 training_arrays.py:325] Your dataset iterator ran out of data; interrupting training. Make sure that your iterator can generate at least `validation_steps * epochs` batches (in this case, 44 batches). You may need touse the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03310, saving model to ./models/01-0.0331-0.9877.hdf5\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "125/125 [==============================] - 915s 7s/step - loss: 0.1639 - accuracy: 0.9320 - val_loss: 0.0331 - val_accuracy: 0.9877\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=3,\n",
    "                    batch_size=1024,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot([1, 2, 3], [0.0331, 0.0256, 0.0223], 'bx-', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot([1, 2, 3], [0.1639, 0.0596, 0.0529], 'ro-', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
